{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xyrion\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Conv2D, SeparableConv2D, concatenate, MaxPooling2D, GlobalAveragePooling2D \n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.unique(y_test)\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "classes = dict(zip(keys,values))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = np.random.choice(50000)\n",
    "plt.imshow(x_train[nb], interpolation='nearest')\n",
    "plt.show()\n",
    "classes[y_train[nb][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddb_b(X_input, growth, repeat=6, **kwargs):\n",
    "    X = X_input\n",
    "    for i in range(repeat):\n",
    "        X = Conv2D(growth, (1,1), strides = 1, **kwargs)(X_input)\n",
    "        X = BatchNormalization()(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = SeparableConv2D(growth, (3,3), strides=1, **kwargs)(X)\n",
    "        X = BatchNormalization()(X)\n",
    "        X = Activation('relu')(X)\n",
    "        \n",
    "        X_input = concatenate([X_input, X], axis = -1)\n",
    "    return X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tinyDSOD_backbone(input_shape, l2):\n",
    "    regul = regularizers.l2(l2)\n",
    "    kwargs = {'padding':'same', 'kernel_regularizer':regul,'kernel_initializer':'glorot_uniform'}\n",
    "\n",
    "    ### STEM ###\n",
    "    # Convolution 1\n",
    "    inp = Input(input_shape)\n",
    "    X = Conv2D(64, (3,3), strides=2, **kwargs)(inp)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Convolution 2\n",
    "    X = Conv2D(64, (1,1), strides=1, **kwargs)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Depth-wise seperable convolution 1\n",
    "    X = SeparableConv2D(64, (3,3), strides=1, **kwargs)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Convolution 3\n",
    "    X = Conv2D(128, (1,1), strides=1, **kwargs)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Depth-wise seperable convolution 2\n",
    "    X = SeparableConv2D(128, (3,3), strides=1, **kwargs)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Pooling\n",
    "    X = MaxPooling2D((2,2), strides=2, padding='same')(X)\n",
    "    \n",
    "    ### Extractor ###\n",
    "    # Dense stage 0\n",
    "    X = ddb_b(X, 32, repeat=4, **kwargs)\n",
    "    \n",
    "    # Transition layer 0\n",
    "    X = Conv2D(128, (1,1), strides=1, **kwargs)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2,2), strides=2, padding='same')(X)\n",
    "    \n",
    "    # Dense stage 1\n",
    "    X = ddb_b(X, 48, repeat = 6, **kwargs)\n",
    "    \n",
    "    # Transition layer 1\n",
    "    X = Conv2D(128, (1,1), strides=1, **kwargs)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2,2), strides=2, padding='same')(X)\n",
    "    \n",
    "    # Dense stage 2\n",
    "    X = ddb_b(X, 64, repeat=6, **kwargs)\n",
    "    \n",
    "    # Transition layer 2\n",
    "    X = Conv2D(256, (1,1), strides=1, **kwargs)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Dense stage 3\n",
    "    X = ddb_b(X, 80, repeat=6, **kwargs)\n",
    "    \n",
    "    # Transition layer 3\n",
    "    X = Conv2D(64, (1,1), strides=1, **kwargs)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    ### Classification layers ###\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "    X = Dense(10, activation='softmax', kernel_regularizer=regul, kernel_initializer='glorot_uniform')(X)\n",
    "    \n",
    "    ### Create Model ### \n",
    "    \n",
    "    model = Model(inputs=inp, outputs=X, name='TinyDSOD_bb')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = tinyDSOD_backbone((32,32,3), l2=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        fill_mode='nearest',\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num in range(5):\n",
    "    model_name = 'MODEL-%01d.h5' % num\n",
    "    print(model_name)\n",
    "    \n",
    "     #We create a checkpoint to save the best model and add an early stopping\n",
    "    checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min')\n",
    "    lr_annealing = ReduceLROnPlateau(monitor='val_loss', patience = 2, epsilon=0.001, factor = 0.25, min_lr = 1e-8, verbose = 1, mode='min' )\n",
    "    callbacks_list = [checkpoint, early_stop, lr_annealing]\n",
    "    \n",
    "    from keras.optimizers import SGD\n",
    "\n",
    "    sgd = SGD(lr=0.1, momentum=0.9)\n",
    "    classification_model.compile(optimizer = sgd, loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    classification_model.fit_generator(\n",
    "                            datagen.flow(x_train, y_train, batch_size=32),\n",
    "                            epochs=200,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            workers=4,\n",
    "                            shuffle = True,\n",
    "                            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
